---
title: "R Notebook - Logistic Regression Homework - Orange Juice Preferences"
output: html_notebook
---


## Objective - build the best predictive classifier you can of whether a customer is likely to buy Citrus Hill or Minute Maid juice. 
##Use logistic regression to do this. 
##Use either train-test splitting or cross-validation to evaluate your classifier. 
##The metric for ‘best classifier’ will be highest AUC value either in the test set (for train-test splitting) or from cross-validation.


```{r}
library(tidyverse)
library(janitor)
library(fastDummies)
library(GGally)
library(ggfortify)
library(mosaic)
library(mosaicData)
library(modelr)
library(readxl)

```

```{r}
library(readr)
oj <- clean_names <- read_csv("data/orange_juice.csv")


  
  
```
```{r}
glimpse(orange_juiceclean)
```

```{r}
skimr::skim(orange_juiceclean) %>% view()
```


```{r}
oj <- orange_juiceclean %>%
  rename(
    week_of_purchase = weekof_purchase,
    store_7 = store7
  ) %>%
  mutate(
    special_ch = as.logical(special_ch),
    special_mm = as.logical(special_mm),
    store_7 = store_7 == "Yes",
    store_id = as_factor(store_id),
    store = as_factor(store)
  )
glimpse(oj)
```




```{r}
orange_summary <-orange_juiceclean%>%
  select(Purchase, WeekofPurchase, PriceCH,PriceMM,LoyalCH)
```

```{r}
ggpairs(orange_summary)
```

```{r}
orange_summaryb <-orange_juiceclean %>%
  select(Purchase, WeekofPurchase,LoyalCH, DiscCH, DiscMM)
```

```{r}
ggpairs(orange_summaryb)
```


```{r}
Orange_f <-orange_summaryb %>%
  mutate(Purchase = ifelse(Purchase == 0, "No", "Yes")) %>%
  mutate_if(is.character, as.factor)
```


```{r}
orange_model <- glm(Purchase ~ LoyalCH, data = Orange_f,
                            family = binomial(link = 'logit'))
summary(orange_model)
```

Not sure this is working at all -





